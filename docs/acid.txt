-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | Artificial Circuit Designer
--   
--   Please see the README on GitHub at
--   <a>https://github.com/augustunderground/acid#readme</a>
@package acid
@version 0.1.0.0


-- | Extensions to Torch
module Torch.Extensions

-- | Swaps the arguments of HaskTorch's foldLoop around
foldLoop' :: Int -> (a -> Int -> IO a) -> a -> IO a

-- | Because snake_case sucks
nanToNum :: Float -> Float -> Float -> Tensor -> Tensor

-- | Default limits for <a>nanToNum</a>
nanToNum' :: Tensor -> Tensor

-- | Default limits for <a>nanToNum</a> (0.0)
nanToNum'' :: Tensor -> Tensor

-- | GPU Tensor filled with Float value
fullLike' :: Tensor -> Float -> Tensor

-- | Select index with [Int] from GPU tensor
indexSelect'' :: Int -> [Int] -> Tensor -> Tensor

-- | Torch.where' with fixed type for where'
where'' :: Tensor -> (Tensor -> Tensor) -> Tensor -> Tensor

-- | Syntactic sugar for HaskTorch's <tt>repeatInterleave</tt> so it can
--   more easily be fmapped.
repeatInterleave' :: Int -> Tensor -> Tensor -> Tensor

-- | Helper function creating split indices as gpu int tensor splits' ::
--   [Int] -&gt; [T.Tensor] splits' = map tit . splits where tit i =
--   T.asTensor (i :: Int)
--   
--   Split Tensor into list of Tensors along dimension
splitDim :: Int -> Tensor -> [Tensor]

-- | Create Boolean Mask Tensor from list of indices.
boolMask :: Int -> [Int] -> Tensor

-- | Create a Boolean Mask Tensor from index Tensor
boolMask' :: Int -> Tensor -> Tensor

-- | GPU 1
gpu :: Device

-- | CPU 0
cpu :: Device

-- | Default Tensor Data Type
dataType :: DType

-- | Convert an Array to a Tensor on GPU
toTensor :: TensorLike a => a -> Tensor

-- | Convert an Array to a Tensor on CPU
toTensor' :: TensorLike a => a -> Tensor

-- | Convert an Array to a Tensor on GPU
toIntTensor :: TensorLike a => a -> Tensor

-- | Convert an Array to a Tensor on CPU
toIntTensor' :: TensorLike a => a -> Tensor

-- | Create an empty Float Tensor on GPU
empty :: Tensor

-- | Create an empty Float Tensor on CPU
empty' :: Tensor

-- | Convert a Scalar to a Tensor on GPU
toScalar :: Float -> Tensor

-- | Convert a Scalar to a Tensor on CPU
toScalar' :: Float -> Tensor

-- | Convert model to Double on GPU
toDouble :: forall a. HasTypes a Tensor => a -> a

-- | Convert model to Double on CPU
toDouble' :: forall a. HasTypes a Tensor => a -> a

-- | Convert model to Float on CPU
toFloat :: forall a. HasTypes a Tensor => a -> a

-- | Convert model to Float on CPU
toFloat' :: forall a. HasTypes a Tensor => a -> a

-- | Generate a Tensor of random Integers on GPU
randomInts :: Int -> Int -> Int -> IO Tensor

-- | Generate a Tensor of random Integers on CPU
randomInts' :: Int -> Int -> Int -> IO Tensor

-- | Generate Normally Distributed Random values given dimensions
normal' :: [Int] -> IO Tensor

-- | Generate Uniformally distributed values in a given range
uniform' :: [Int] -> Float -> Float -> IO Tensor

-- | Rescale tensor s.t. mean = 0.0 and std = 1.0
rescale :: Tensor -> Tensor


-- | Utility and Helper functions for EDELWACE
module Lib

-- | Available Algorithms
data Algorithm

-- | Twin Delayed Deep Deterministic Policy Gradient
TD3 :: Algorithm

-- | Soft Actor Critic
SAC :: Algorithm

-- | Proximal Policy Optimization
PPO :: Algorithm

-- | Available Replay Buffer Types
data ReplayMemory

-- | Vanilla Replay Buffer
RPB :: ReplayMemory

-- | Prioritized Experience Replay
PER :: ReplayMemory

-- | PPO Style replay Memory
MEM :: ReplayMemory

-- | Emphasizing Recent Experience
ERE :: ReplayMemory

-- | Hindsight Experience Replay
HER :: ReplayMemory

-- | Hindsight Experience Replay Strategies for choosing Goals
data Strategy

-- | Only Final States are additional targets
Final :: Strategy

-- | Replay with <tt>k</tt> random states encountered so far (basically
--   vanilla)
Random :: Strategy

-- | Replay with <tt>k</tt> random states from same episode.
Episode :: Strategy

-- | Replay with <tt>k</tt> random states from same episode, that were
--   observed after
Future :: Strategy

-- | Run Mode
data Mode

-- | Start Agent Training
Train :: Mode

-- | Continue Agent Training
Cont :: Mode

-- | Evaluate Agent
Eval :: Mode

-- | Command Line Arguments
data Args
Args :: String -> String -> String -> String -> String -> String -> String -> String -> String -> String -> String -> String -> Args

-- | Circus Server Host Address
[cktHost] :: Args -> String

-- | Circus Server Port
[cktPort] :: Args -> String

-- | ACE Circuit ID
[cktId] :: Args -> String

-- | ACE Backend / PDK
[cktBackend] :: Args -> String

-- | Design Space
[cktSpace] :: Args -> String

-- | RL Algorithm
[algorithm] :: Args -> String

-- | Replay Buffer
[buffer] :: Args -> String

-- | Checkpoint Base Path
[path] :: Args -> String

-- | MLFlow Server Host Address
[mlfHost] :: Args -> String

-- | MLFlow Server Port
[mlfPort] :: Args -> String

-- | Run Mode
[mode] :: Args -> String

-- | File Path to config.yaml
[config] :: Args -> String

-- | Type Alias for Transition Tuple (state, action, reward, state', done)
type Transition = (Tensor, Tensor, Tensor, Tensor, Tensor)

-- | Calculate success rate given 1D Boolean done Tensor
successRate :: Tensor -> Float

-- | Range from 0 to n - 1
range :: Int -> [Int]

-- | First of triple
fst' :: (a, b, c) -> a

-- | Delete multiple elements from a Set
delete' :: Ord a => [a] -> Set a -> Set a

-- | Helper function creating split indices
splits :: [Int] -> [[Int]]

-- | First of Triple
fst3 :: (a, b, c) -> a

-- | Apply a function to both elements of a Tuple
both :: (a -> b) -> (a, a) -> (b, b)

-- | Uncurry Triple
uncurry3 :: (a -> b -> c -> d) -> (a, b, c) -> d

-- | Like <a>lookup</a> but for a list of keys.
lookup' :: Ord k => [k] -> Map k a -> Maybe [a]

-- | Map an appropriate function over a transition tuple
tmap :: (Tensor -> Tensor) -> Transition -> Transition

-- | Infix div
(//) :: Integral a => a -> a -> a

-- | Infix mod
(%) :: Integral a => a -> a -> a

-- | Current Timestamp as formatted string
currentTimeStamp :: String -> IO String

-- | Current Timestamp with default formatting: "%Y%m%d-%H%M%S"
currentTimeStamp' :: IO String

-- | Create a model archive directory for the given algorithm
createModelArchiveDir :: String -> IO String

-- | Create a model archive directory for the given algorithm, ace id and
--   backend
createModelArchiveDir' :: String -> String -> String -> String -> String -> String -> IO String

-- | Optimizer moments at given prefix
saveOptim :: Adam -> FilePath -> IO ()

-- | Load Optimizer State
loadOptim :: Int -> Float -> Float -> FilePath -> IO Adam

-- | Calculate weight Limits based on Layer Dimensions
weightLimit :: Linear -> Float

-- | Type of weight initialization
data Initializer

-- | Normally distributed weights
Normal :: Initializer

-- | Uniformally distributed weights
Uniform :: Initializer

-- | Using T.xavierNormal
XavierNormal :: Initializer

-- | Using T.xavierUniform
XavierUniform :: Initializer

-- | Using T.kaimingNormal
KaimingNormal :: Initializer

-- | Using T.kaimingUniform
KaimingUniform :: Initializer
Dirac :: Initializer
Eye :: Initializer
Ones :: Initializer
Zeros :: Initializer
Constant :: Initializer

-- | Weights for a layer given limits and dimensions.
initWeights :: Initializer -> Float -> Float -> [Int] -> IO IndependentTensor

-- | Initialize Weights of Linear Layer
weightInit :: Initializer -> Float -> Float -> Linear -> IO Linear

-- | Initialize Weights and Bias of Linear Layer
weightInit' :: Initializer -> Float -> Float -> Linear -> IO Linear

-- | Initialize weights uniformally given upper and lower bounds
weightInitUniform :: Float -> Float -> Linear -> IO Linear

-- | Initialize weights uniformally based on Fan In
weightInitUniform' :: Linear -> IO Linear

-- | Initialize weights normally given mean and std bounds
weightInitNormal :: Float -> Float -> Linear -> IO Linear

-- | Initialize weights normally based on Fan In
weightInitNormal' :: Linear -> IO Linear

-- | Softly update parameters from Online Net to Target Net
softUpdate :: Tensor -> Tensor -> Tensor -> Tensor

-- | Softly copy parameters from Online Net to Target Net
softSync :: Parameterized f => Tensor -> f -> f -> IO f

-- | Hard Copy of Parameter from one net to the other
copySync :: Parameterized f => f -> f -> f
instance Data.Aeson.Types.ToJSON.ToJSON Lib.Algorithm
instance Data.Aeson.Types.FromJSON.FromJSON Lib.Algorithm
instance GHC.Generics.Generic Lib.Algorithm
instance GHC.Read.Read Lib.Algorithm
instance GHC.Show.Show Lib.Algorithm
instance GHC.Classes.Eq Lib.Algorithm
instance Data.Aeson.Types.ToJSON.ToJSON Lib.ReplayMemory
instance Data.Aeson.Types.FromJSON.FromJSON Lib.ReplayMemory
instance GHC.Generics.Generic Lib.ReplayMemory
instance GHC.Read.Read Lib.ReplayMemory
instance GHC.Show.Show Lib.ReplayMemory
instance GHC.Classes.Eq Lib.ReplayMemory
instance Data.Aeson.Types.ToJSON.ToJSON Lib.Strategy
instance Data.Aeson.Types.FromJSON.FromJSON Lib.Strategy
instance GHC.Generics.Generic Lib.Strategy
instance GHC.Read.Read Lib.Strategy
instance GHC.Show.Show Lib.Strategy
instance GHC.Classes.Eq Lib.Strategy
instance GHC.Read.Read Lib.Mode
instance GHC.Show.Show Lib.Mode
instance GHC.Classes.Eq Lib.Mode
instance GHC.Show.Show Lib.Args


-- | Circuis REST API Communication
module CKT

-- | Available Circuits
data Circuit

-- | Miller Amplifier (op1)
OP1 :: Circuit

-- | Symmetrical Amplifier (op2)
OP2 :: Circuit

-- | Folded Cascode (op8)
OP8 :: Circuit

-- | Available PDKs
data PDK

-- | X-Fab XH035 350nm Process
XH035 :: PDK

-- | X-Fab XH018 180nm Process
XH018 :: PDK

-- | Available Design / Action Spaces
data Space

-- | Electric Design Space
Electric :: Space

-- | Geometric Design Space
Geometric :: Space

-- | Base Route to Cricus Server
type CircusUrl = String

-- | Generate URL to a Circuit server from meta information
url :: String -> String -> String -> String -> String -> String -> CircusUrl

-- | Get the number of Environments from the given Circus Server instance
numEnvs :: CircusUrl -> IO Int

-- | Get the number of Environments from the given Circus Server instance
actionSpace :: CircusUrl -> IO Int

-- | Get the number of Environments from the given Circus Server instance
observationSpace :: CircusUrl -> IO (Int, Int, Int)

-- | Reset Environments and get (observation, achieved_goal, desired_goal)
reset :: CircusUrl -> IO (Tensor, Tensor, Tensor)

-- | Reset subset of environments with given mask
reset' :: CircusUrl -> Tensor -> IO (Tensor, Tensor, Tensor)

-- | Shorthand for taking a Tensor action and returning Tensors
step :: CircusUrl -> Tensor -> IO (Tensor, Tensor, Tensor, Tensor, Tensor)

-- | Shorthand for getting Tensors
randomAction :: CircusUrl -> IO Tensor

-- | Shorthand for calculating reward given Tensors
calculateReward :: CircusUrl -> Tensor -> Tensor -> IO Tensor

-- | Observation returned from Stepping / Resetting Environment
data Observation a
Observation :: !a -> !a -> !a -> Maybe [Bool] -> Maybe [Float] -> Maybe [Info] -> Observation a

-- | State
[observation] :: Observation a -> !a

-- | Achieved Goal
[achievedGoal] :: Observation a -> !a

-- | Desired Goal
[desiredGoal] :: Observation a -> !a

-- | Terminal Flag
[done] :: Observation a -> Maybe [Bool]

-- | Rewards
[reward] :: Observation a -> Maybe [Float]

-- | Info Dict
[info] :: Observation a -> Maybe [Info]

-- | Info Dict returned from Environment
data Info
Info :: ![String] -> ![String] -> ![String] -> Info

-- | Goal Parameters
[goal] :: Info -> ![String]

-- | Parameters in Action Vector
[inputs] :: Info -> ![String]

-- | Parameters in State Vector
[outputs] :: Info -> ![String]

-- | Action passed to Environment
newtype Action a
Action :: a -> Action a
[action] :: Action a -> a

-- | Shorthand for getting Performance
currentPerformance :: CircusUrl -> IO (Map Int (Map String Float))

-- | Shorthand for getting Goal
currentGoal :: CircusUrl -> IO (Map Int (Map String Float))

-- | Shorthand for getting Sizing
currentSizing :: CircusUrl -> IO (Map Int (Map String Float))

-- | Shorthand for getting last Action
lastAction :: CircusUrl -> IO (Map Int (Map String Float))
instance Data.Aeson.Types.ToJSON.ToJSON CKT.Circuit
instance Data.Aeson.Types.FromJSON.FromJSON CKT.Circuit
instance GHC.Generics.Generic CKT.Circuit
instance GHC.Classes.Eq CKT.Circuit
instance Data.Aeson.Types.ToJSON.ToJSON CKT.PDK
instance Data.Aeson.Types.FromJSON.FromJSON CKT.PDK
instance GHC.Generics.Generic CKT.PDK
instance GHC.Classes.Eq CKT.PDK
instance Data.Aeson.Types.ToJSON.ToJSON CKT.Space
instance Data.Aeson.Types.FromJSON.FromJSON CKT.Space
instance GHC.Generics.Generic CKT.Space
instance GHC.Classes.Eq CKT.Space
instance GHC.Show.Show CKT.Info
instance GHC.Generics.Generic CKT.Info
instance GHC.Show.Show a => GHC.Show.Show (CKT.Action a)
instance GHC.Generics.Generic (CKT.Action a)
instance GHC.Show.Show a => GHC.Show.Show (CKT.Observation a)
instance GHC.Generics.Generic (CKT.Observation a)
instance Data.Aeson.Types.FromJSON.FromJSON (CKT.Observation [[GHC.Types.Float]])
instance Data.Aeson.Types.ToJSON.ToJSON (CKT.Observation [[GHC.Types.Float]])
instance GHC.Base.Functor CKT.Observation
instance Data.Aeson.Types.FromJSON.FromJSON (CKT.Action [[GHC.Types.Float]])
instance Data.Aeson.Types.ToJSON.ToJSON (CKT.Action [[GHC.Types.Float]])
instance GHC.Base.Functor CKT.Action
instance Data.Aeson.Types.FromJSON.FromJSON CKT.Info
instance Data.Aeson.Types.ToJSON.ToJSON CKT.Info
instance GHC.Show.Show CKT.Space
instance GHC.Read.Read CKT.Space
instance GHC.Show.Show CKT.PDK
instance GHC.Read.Read CKT.PDK
instance GHC.Show.Show CKT.Circuit
instance GHC.Read.Read CKT.Circuit


-- | ACiD Specific Extensions to the mlflow-hs package
module MLFlow.Extensions

-- | Sanatize JSON for MLFlow: Names may only contain alphanumerics,
--   underscores (_), dashes (-), periods (.), spaces ( ), and slashes (/).
sanatizeJSON :: Char -> Char

-- | Data Logging to MLFlow Trackign Server
data Tracker
Tracker :: TrackingURI -> ExperimentID -> String -> Map String RunID -> Tracker

-- | Tracking Server URI
[uri] :: Tracker -> TrackingURI

-- | Experiment ID
[experimentId] :: Tracker -> ExperimentID

-- | Experiment Name
[experimentName] :: Tracker -> String

-- | Run IDs
[runIds] :: Tracker -> Map String RunID

-- | Retrieve a run ID
runId :: Tracker -> String -> RunID

-- | Make new Tracker given a Tracking Server URI
mkTracker :: TrackingURI -> String -> IO Tracker

-- | Make new Tracker given a Hostname and Port
mkTracker' :: String -> Int -> String -> IO Tracker

-- | Create a new Experiment with rng suffix
newExperiment :: Tracker -> String -> IO Tracker

-- | Create a new Experiment
newExperiment' :: Tracker -> String -> IO Tracker

-- | Create a new run with a set of given paramters
newRuns :: Tracker -> [String] -> [Param] -> IO Tracker

-- | New run with algorithm id and #envs as log params
newRuns' :: Int -> Tracker -> IO Tracker

-- | End a run
endRun :: String -> Tracker -> IO Tracker

-- | End all runs of a Tracker
endRuns :: Tracker -> IO Tracker

-- | End all runs and discard tracker
endRuns' :: Tracker -> IO ()

-- | Write Loss to Tracking Server
trackLoss :: Tracker -> Int -> String -> Float -> IO (Response ByteString)

-- | Write Reward to Tracking Server
trackReward :: Tracker -> Int -> Tensor -> IO ()

-- | Clean up a Map returned by Circus Server
sanatizeMap :: Map Int (Map String Float) -> Map Int (Map String Float)

-- | Write Current state of the Environment to Trackign Server
trackEnvState :: Tracker -> CircusUrl -> Int -> IO ()
instance GHC.Show.Show MLFlow.Extensions.Tracker


-- | Twin Delayed Deep Deterministic Policy Gradient Algorithm Defaults
module HyperParameters.Defaults

-- | Number of episodes to play
numEpisodes :: Int

-- | Maximum Number of Steps per Episode
horizonT :: Int

-- | Number of epochs to train
numEpochs :: Int

-- | Mini batch size
batchSize :: Int

-- | Random seed for reproducibility
rngSeed :: Int

-- | Action space lower bound
actionLow :: Float

-- | Action space upper bound
actionHigh :: Float

-- | Policy and Target Update Delay
d :: Int

-- | Noise clipping
c :: Float

-- | Discount Factor
γ :: Tensor

-- | Soft Update coefficient (sometimes "polyak") of the target networks τ
--   ∈ [0,1]
τ :: Tensor

-- | Decay Period
decayPeriod :: Int

-- | Noise Clipping Minimum
σMin :: Float

-- | Noise Clipping Maximum
σMax :: Float

-- | Evaluation Noise standard deviation (σ~)
σEval :: Tensor

-- | Action Noise standard deviation
σAct :: Tensor

-- | Noise Clipping
σClip :: Float

-- | Number of units per hidden layer
hidDim :: Int

-- | Initial weights
wInit :: Float

-- | Actor Learning Rate
ηφ :: Tensor

-- | Critic Learning Rate
ηθ :: Tensor

-- | ADAM Hyper Parameter β1
β1 :: Float

-- | ADAM Hyper Parameter β2
β2 :: Float

-- | Leaky ReLU Slope
negativeSlope :: Float

-- | Replay Buffer Size
bufferSize :: Int

-- | Frequency of random exploration Episodes
explFreq :: Int

-- | Frequency of Evaluation Episodes
evalFreq :: Int

-- | Number of Additional Targets to sample
k :: Int


-- | Hyper Parameter Configuration
module HyperParameters

-- | Read a Tensor from float
read' :: Float -> Maybe Tensor

-- | Read a Tensor from float
read'' :: Float -> Maybe Tensor

-- | Decode / Parse ByteString to Meta
parseConfig' :: ByteString -> Params

-- | Decode / Parse Params File
parseConfig :: FilePath -> IO Params

-- | Configuration Parameters Information
data Params
Params :: Int -> Int -> Int -> Int -> Float -> Tensor -> Tensor -> Int -> Float -> Float -> Tensor -> Tensor -> Float -> Int -> Float -> Tensor -> Tensor -> Float -> Float -> Float -> Int -> Strategy -> Float -> Float -> Int -> Int -> Int -> Int -> Int -> Params

-- | Random seed for reproducibility
[rngSeed] :: Params -> Int

-- | Number of episodes to play
[numEpisodes] :: Params -> Int

-- | Maximum Number of Steps per Episode
[horizonT] :: Params -> Int

-- | Policy and Target Update Delay
[d] :: Params -> Int

-- | Noise clipping
[c] :: Params -> Float

-- | Discount Factor (Tensor)
[γ] :: Params -> Tensor

-- | Soft Update coefficient ("polyak") τ ∈ [0,1]
[τ] :: Params -> Tensor

-- | Decay Period
[decay] :: Params -> Int

-- | Noise Clipping Minimum
[σMin] :: Params -> Float

-- | Noise Clipping Maximum
[σMax] :: Params -> Float

-- | Evaluation Noise standard deviation (σ~) (Tensor)
[σEval] :: Params -> Tensor

-- | Action Noise standard deviation (Tensor)
[σAct] :: Params -> Tensor

-- | Noise Clipping
[σClip] :: Params -> Float

-- | Number of units per hidden layer
[hidDim] :: Params -> Int

-- | Initial weights
[wInit] :: Params -> Float

-- | Actor Learning Rate (Tensor)
[ηφ] :: Params -> Tensor

-- | Critic Learning Rate (Tensor)
[ηθ] :: Params -> Tensor

-- | ADAM Hyper Parameter β1
[β1] :: Params -> Float

-- | ADAM Hyper Parameter β2
[β2] :: Params -> Float

-- | Leaky ReLU Slope
[lreluSlope] :: Params -> Float

-- | Number of Additional Targets to sample
[k] :: Params -> Int

-- | Goal Sampling Strategy
[strategy] :: Params -> Strategy

-- | Action space lower bound
[actionLow] :: Params -> Float

-- | Action space upper bound
[actionHigh] :: Params -> Float

-- | Number of epochs to train
[numEpochs] :: Params -> Int

-- | Frequency of random exploration episodes
[explFreq] :: Params -> Int

-- | Frequency of random exploration episodes
[evalFreq] :: Params -> Int

-- | Replay Buffer Size
[bufferSize] :: Params -> Int

-- | Mini batch size
[batchSize] :: Params -> Int
instance GHC.Show.Show HyperParameters.Params
instance GHC.Generics.Generic HyperParameters.Params
instance Data.Aeson.Types.FromJSON.FromJSON HyperParameters.Params
instance Data.Aeson.Types.ToJSON.ToJSON HyperParameters.Params


-- | General Replay Buffer Types and TypeClasses
module ALG

-- | Replay Buffer Interface
class Agent a

-- | Save an agent at a given Path
saveAgent :: Agent a => FilePath -> a -> IO a

-- | Load an agent saved at a Path
loadAgent :: Agent a => Params -> FilePath -> Int -> Int -> Int -> IO a

-- | Take an action to the best Ability
act :: Agent a => a -> Tensor -> IO Tensor

-- | Take a noisy action
act' :: Agent a => a -> Tensor -> IO Tensor

-- | Take an action without any noise
act'' :: Agent a => a -> Tensor -> Tensor

-- | Update Policy
updatePolicy :: Agent a => Params -> CircusUrl -> Tracker -> Int -> [Transition] -> a -> IO a


-- | General Replay Buffer Types and TypeClasses
module RPB

-- | Replay Buffer Interface
class (Functor b) => ReplayBuffer b

-- | Return size of current buffer
size :: ReplayBuffer b => b Tensor -> Int

-- | Push one buffer into another
push :: ReplayBuffer b => Int -> b Tensor -> b Tensor -> b Tensor

-- | Look Up given list if indices
lookUp :: ReplayBuffer b => [Int] -> b Tensor -> b Tensor

-- | Take n Random Samples
sampleIO :: ReplayBuffer b => Int -> b Tensor -> IO (b Tensor)

-- | Return the Tuple: (s, a, r, s', d) for training
asTuple :: ReplayBuffer b => b Tensor -> (Tensor, Tensor, Tensor, Tensor, Tensor)

-- | Collect Experiences in Buffer
collectExperience :: (ReplayBuffer b, Agent a) => Params -> CircusUrl -> Tracker -> Int -> a -> IO (b Tensor)

-- | Generate a list of uniformly sampled minibatches
randomBatches :: ReplayBuffer b => Int -> Int -> b Tensor -> IO [Transition]

-- | Vanilla Replay Buffer
data Buffer a
Buffer :: !a -> !a -> !a -> !a -> !a -> Buffer a

-- | States
[states] :: Buffer a -> !a

-- | Actions
[actions] :: Buffer a -> !a

-- | Rewards
[rewards] :: Buffer a -> !a

-- | Next States
[states'] :: Buffer a -> !a

-- | Terminal Mask
[dones] :: Buffer a -> !a

-- | Create a new, empty Buffer on the CPU
empty :: Buffer Tensor

-- | How many Trajectories are currently stored in memory
size' :: Buffer Tensor -> Int

-- | Drop number of entries from the beginning of the Buffer
drop :: Int -> Buffer Tensor -> Buffer Tensor

-- | Push one buffer into another one
push' :: Int -> Buffer Tensor -> Buffer Tensor -> Buffer Tensor

-- | Get the given indices from Buffer
lookUp' :: [Int] -> Buffer Tensor -> Buffer Tensor

-- | Take n random samples from Buffer
sampleIO' :: Int -> Buffer Tensor -> IO (Buffer Tensor)

-- | Return (State, Action, Reward, Next State, Done) Tuple
asTuple' :: Buffer Tensor -> Transition

-- | Evaluate Policy for T steps and return experience Buffer
collectStep :: Agent a => Params -> CircusUrl -> Tracker -> Int -> Int -> a -> Tensor -> Buffer Tensor -> IO (Buffer Tensor)

-- | Collect experience for a given number of steps
collectExperience' :: Agent a => Params -> CircusUrl -> Tracker -> Int -> a -> IO (Buffer Tensor)
instance GHC.Classes.Eq a => GHC.Classes.Eq (RPB.Buffer a)
instance GHC.Show.Show a => GHC.Show.Show (RPB.Buffer a)
instance GHC.Base.Functor RPB.Buffer
instance GHC.Base.Applicative RPB.Buffer
instance RPB.ReplayBuffer RPB.Buffer


-- | Hindsight Experience Replay
module RPB.HER

-- | Hindsight Experience Replay Strategies for choosing Goals
data Strategy

-- | Only Final States are additional targets
Final :: Strategy

-- | Replay with <tt>k</tt> random states encountered so far (basically
--   vanilla)
Random :: Strategy

-- | Replay with <tt>k</tt> random states from same episode.
Episode :: Strategy

-- | Replay with <tt>k</tt> random states from same episode, that were
--   observed after
Future :: Strategy

-- | Strict Simple/Naive Replay Buffer
data Buffer a
Buffer :: !a -> !a -> !a -> !a -> !a -> !a -> !a -> Buffer a

-- | States
[states] :: Buffer a -> !a

-- | Actions
[actions] :: Buffer a -> !a

-- | Rewards
[rewards] :: Buffer a -> !a

-- | Next States
[states'] :: Buffer a -> !a

-- | Terminal Mask
[dones] :: Buffer a -> !a

-- | Desired Goal
[goals] :: Buffer a -> !a

-- | Acheived Goal
[goals'] :: Buffer a -> !a

-- | Construct an empty HER Buffer
empty :: Buffer Tensor

-- | Split buffer collected from pool by env
envSplit :: Int -> Buffer Tensor -> [Buffer Tensor]

-- | Split a buffer into episodes, dropping the last unfinished
epsSplit :: Buffer Tensor -> [Buffer Tensor]

-- | Sample Additional Goals according to Strategy (drop first).
--   <a>Random</a> is basically the same as <a>Episode</a> you just have to
--   give it the entire buffer, not just the episode.
sampleGoals :: CircusUrl -> Strategy -> Int -> Buffer Tensor -> IO (Buffer Tensor)
instance GHC.Classes.Eq a => GHC.Classes.Eq (RPB.HER.Buffer a)
instance GHC.Show.Show a => GHC.Show.Show (RPB.HER.Buffer a)
instance GHC.Base.Functor RPB.HER.Buffer
instance GHC.Base.Applicative RPB.HER.Buffer
instance RPB.ReplayBuffer RPB.HER.Buffer


-- | Twin Delayed Deep Deterministic Policy Gradient Algorithm
module ALG.TD3

-- | Actor Network Architecture
data PolicyNet
PolicyNet :: Linear -> Linear -> Linear -> PolicyNet
[pLayer0] :: PolicyNet -> Linear
[pLayer1] :: PolicyNet -> Linear
[pLayer2] :: PolicyNet -> Linear

-- | Critic Network Architecture
data CriticNet
CriticNet :: Linear -> Linear -> Linear -> Linear -> Linear -> Linear -> CriticNet
[q1Layer0] :: CriticNet -> Linear
[q1Layer1] :: CriticNet -> Linear
[q1Layer2] :: CriticNet -> Linear
[q2Layer0] :: CriticNet -> Linear
[q2Layer1] :: CriticNet -> Linear
[q2Layer2] :: CriticNet -> Linear

-- | TD3 Agent
data Agent
Agent :: PolicyNet -> PolicyNet -> CriticNet -> CriticNet -> Adam -> Adam -> Float -> Float -> Tensor -> Tensor -> Float -> Agent

-- | Online Policy φ
[φ] :: Agent -> PolicyNet

-- | Target Policy φ'
[φ'] :: Agent -> PolicyNet

-- | Online Critic θ
[θ] :: Agent -> CriticNet

-- | Target Critic θ
[θ'] :: Agent -> CriticNet

-- | Policy Optimizer
[φOptim] :: Agent -> Adam

-- | Critic Optimizer
[θOptim] :: Agent -> Adam

-- | Lower bound of Action space
[actLo] :: Agent -> Float

-- | Upper bound of Action space
[actHi] :: Agent -> Float

-- | Action Noise
[σA] :: Agent -> Tensor

-- | Eval Noise
[σE] :: Agent -> Tensor

-- | Noise Clipping
[c'] :: Agent -> Float

-- | Agent constructor
mkAgent :: Params -> Int -> Int -> IO Agent

-- | Save an Agent and return the agent
saveAgent' :: FilePath -> Agent -> IO ()
instance GHC.Classes.Eq ALG.TD3.PolicyNetSpec
instance GHC.Show.Show ALG.TD3.PolicyNetSpec
instance GHC.Classes.Eq ALG.TD3.CriticNetSpec
instance GHC.Show.Show ALG.TD3.CriticNetSpec
instance Torch.NN.Parameterized ALG.TD3.PolicyNet
instance GHC.Show.Show ALG.TD3.PolicyNet
instance GHC.Generics.Generic ALG.TD3.PolicyNet
instance Torch.NN.Parameterized ALG.TD3.CriticNet
instance GHC.Show.Show ALG.TD3.CriticNet
instance GHC.Generics.Generic ALG.TD3.CriticNet
instance GHC.Show.Show ALG.TD3.Agent
instance GHC.Generics.Generic ALG.TD3.Agent
instance ALG.Agent ALG.TD3.Agent
instance Torch.NN.Randomizable ALG.TD3.CriticNetSpec ALG.TD3.CriticNet
instance Torch.NN.Randomizable ALG.TD3.PolicyNetSpec ALG.TD3.PolicyNet


-- | Artificial Circuit Designer
module ACiD

-- | Policy evaluation Episode
eval :: Agent a => Params -> CircusUrl -> Tracker -> a -> Int -> Int -> Tensor -> Tensor -> IO ()

-- | Runs training on given Agent with Buffer
train :: (Agent a, ReplayBuffer b) => Params -> CircusUrl -> Tracker -> String -> Int -> b Tensor -> a -> IO ()

-- | Create Agent and Buffer, then run training
run' :: Params -> CircusUrl -> Tracker -> String -> Mode -> Algorithm -> ReplayMemory -> IO ()

-- | Clown School
run :: Args -> IO ()
